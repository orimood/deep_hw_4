{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# GAN and cGAN for Tabular Data Generation\n",
    "\n",
    "## Assignment 4: Deep Learning\n",
    "\n",
    "This notebook implements:\n",
    "1. **GAN** - Standard GAN for synthetic tabular data generation\n",
    "2. **cGAN** - Conditional GAN with label conditioning\n",
    "\n",
    "## Key Design Decisions\n",
    "- **WGAN-GP**: Wasserstein loss with gradient penalty for stable training\n",
    "- **Mixture Model**: Explicit handling of zero-inflated features (capital-gain, capital-loss) and peak values (hours-per-week=40)\n",
    "- **Gumbel-Softmax**: Differentiable categorical sampling\n",
    "- **Label Conditioning**: cGAN concatenates one-hot label to both generator input and discriminator input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (32561, 15)\n",
      "\n",
      "Target distribution:\n",
      "income\n",
      "<=50K    0.75919\n",
      ">50K     0.24081\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data, meta = arff.loadarff('../data/adult.arff')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Decode bytes to strings\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "        df[col] = df[col].str.decode('utf-8')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['income'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 3. Feature Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Configuration:\n",
      "  Zero-inflated: ['capital-gain', 'capital-loss']\n",
      "  Peak-inflated: ['hours-per-week']\n",
      "  Log-transform: ['fnlwgt']\n",
      "  Continuous: ['age', 'fnlwgt']\n",
      "  Discrete as categorical: ['education-num']\n",
      "  Categorical: ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n"
     ]
    }
   ],
   "source": [
    "# Feature categorization\n",
    "ZERO_INFLATED = ['capital-gain', 'capital-loss']  # ~90%+ zeros\n",
    "PEAK_INFLATED = ['hours-per-week']  # 47% at value 40\n",
    "PEAK_VALUES = {'hours-per-week': 40}\n",
    "\n",
    "# Log-transform for right-skewed features\n",
    "LOG_TRANSFORM = ['fnlwgt']\n",
    "\n",
    "CONTINUOUS = ['age', 'fnlwgt']  # fnlwgt gets log transform\n",
    "\n",
    "# Treat education-num as categorical (16 discrete values)\n",
    "DISCRETE_AS_CATEGORICAL = ['education-num']\n",
    "\n",
    "CATEGORICAL = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "               'relationship', 'race', 'sex', 'native-country']\n",
    "\n",
    "TARGET = 'income'\n",
    "N_CLASSES = 2  # <=50K, >50K\n",
    "\n",
    "print(\"Feature Configuration:\")\n",
    "print(f\"  Zero-inflated: {ZERO_INFLATED}\")\n",
    "print(f\"  Peak-inflated: {PEAK_INFLATED}\")\n",
    "print(f\"  Log-transform: {LOG_TRANSFORM}\")\n",
    "print(f\"  Continuous: {CONTINUOUS}\")\n",
    "print(f\"  Discrete as categorical: {DISCRETE_AS_CATEGORICAL}\")\n",
    "print(f\"  Categorical: {CATEGORICAL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 4. Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    \"\"\"Preprocess tabular data for GAN training.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scalers = {}\n",
    "        self.zero_props = {}\n",
    "        self.peak_props = {}\n",
    "        self.cat_mappings = {}\n",
    "        self.cat_dims = {}\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.mode_values = {}\n",
    "        self.feature_info = []  # (name, type, dim)\n",
    "        self.log_transform = LOG_TRANSFORM\n",
    "        \n",
    "    def fit(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Handle missing values in categorical\n",
    "        for col in CATEGORICAL:\n",
    "            valid = df[df[col] != '?'][col]\n",
    "            if len(valid) > 0:\n",
    "                self.mode_values[col] = valid.mode()[0]\n",
    "                df[col] = df[col].replace('?', self.mode_values[col])\n",
    "        \n",
    "        # Zero-inflated features\n",
    "        for col in ZERO_INFLATED:\n",
    "            self.zero_props[col] = (df[col] == 0).mean()\n",
    "            non_zero = df[df[col] > 0][col].values\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(non_zero.reshape(-1, 1))\n",
    "            self.scalers[col] = scaler\n",
    "            self.feature_info.append((col, 'zero_inflated', 2))\n",
    "        \n",
    "        # Peak-inflated features\n",
    "        for col in PEAK_INFLATED:\n",
    "            peak_val = PEAK_VALUES[col]\n",
    "            self.peak_props[col] = (df[col] == peak_val).mean()\n",
    "            non_peak = df[df[col] != peak_val][col].values\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(non_peak.reshape(-1, 1))\n",
    "            self.scalers[col] = scaler\n",
    "            self.feature_info.append((col, 'peak_inflated', 2))\n",
    "        \n",
    "        # Continuous features (with optional log transform)\n",
    "        for col in CONTINUOUS:\n",
    "            values = df[col].values.copy().astype(np.float64)\n",
    "            if col in self.log_transform:\n",
    "                values = np.log1p(values)\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(values.reshape(-1, 1))\n",
    "            self.scalers[col] = scaler\n",
    "            self.feature_info.append((col, 'continuous', 1))\n",
    "        \n",
    "        # Discrete features treated as categorical\n",
    "        for col in DISCRETE_AS_CATEGORICAL:\n",
    "            unique_vals = sorted(df[col].unique())\n",
    "            self.cat_mappings[col] = {v: i for i, v in enumerate(unique_vals)}\n",
    "            self.cat_dims[col] = len(unique_vals)\n",
    "            self.feature_info.append((col, 'categorical', len(unique_vals)))\n",
    "        \n",
    "        # Categorical features\n",
    "        for col in CATEGORICAL:\n",
    "            unique_vals = sorted(df[col].unique())\n",
    "            self.cat_mappings[col] = {v: i for i, v in enumerate(unique_vals)}\n",
    "            self.cat_dims[col] = len(unique_vals)\n",
    "            self.feature_info.append((col, 'categorical', len(unique_vals)))\n",
    "        \n",
    "        self.label_encoder.fit(df[TARGET])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        for col, mode in self.mode_values.items():\n",
    "            df[col] = df[col].replace('?', mode)\n",
    "        \n",
    "        arrays = []\n",
    "        \n",
    "        # Zero-inflated\n",
    "        for col in ZERO_INFLATED:\n",
    "            is_zero = (df[col] == 0).astype(np.float32).values.reshape(-1, 1)\n",
    "            values = df[col].values.copy().astype(np.float32)\n",
    "            mask = values > 0\n",
    "            if mask.any():\n",
    "                values[mask] = self.scalers[col].transform(values[mask].reshape(-1, 1)).flatten()\n",
    "            values[~mask] = 0  # When zero, value column = 0\n",
    "            arrays.extend([is_zero, values.reshape(-1, 1)])\n",
    "        \n",
    "        # Peak-inflated\n",
    "        for col in PEAK_INFLATED:\n",
    "            peak_val = PEAK_VALUES[col]\n",
    "            is_peak = (df[col] == peak_val).astype(np.float32).values.reshape(-1, 1)\n",
    "            values = df[col].values.copy().astype(np.float32)\n",
    "            mask = values != peak_val\n",
    "            if mask.any():\n",
    "                values[mask] = self.scalers[col].transform(values[mask].reshape(-1, 1)).flatten()\n",
    "            values[~mask] = 0.5  # When peak, value column = 0.5\n",
    "            arrays.extend([is_peak, values.reshape(-1, 1)])\n",
    "        \n",
    "        # Continuous (with optional log transform)\n",
    "        for col in CONTINUOUS:\n",
    "            values = df[col].values.copy().astype(np.float64)\n",
    "            if col in self.log_transform:\n",
    "                values = np.log1p(values)\n",
    "            scaled = self.scalers[col].transform(values.reshape(-1, 1))\n",
    "            arrays.append(scaled.astype(np.float32))\n",
    "        \n",
    "        # Discrete as categorical + Categorical\n",
    "        for col in DISCRETE_AS_CATEGORICAL + CATEGORICAL:\n",
    "            n_cat = self.cat_dims[col]\n",
    "            onehot = np.zeros((len(df), n_cat), dtype=np.float32)\n",
    "            for i, val in enumerate(df[col]):\n",
    "                if val in self.cat_mappings[col]:\n",
    "                    onehot[i, self.cat_mappings[col][val]] = 1\n",
    "            arrays.append(onehot)\n",
    "        \n",
    "        X = np.hstack(arrays)\n",
    "        y = self.label_encoder.transform(df[TARGET])\n",
    "        return X, y\n",
    "    \n",
    "    def get_dim(self):\n",
    "        return sum(d for _, _, d in self.feature_info)\n",
    "    \n",
    "    def get_continuous_indices(self):\n",
    "        \"\"\"Get indices of continuous feature values for distribution losses.\"\"\"\n",
    "        indices = []\n",
    "        pos = 0\n",
    "        for name, ftype, dim in self.feature_info:\n",
    "            if ftype == 'zero_inflated':\n",
    "                indices.append((name, 'zero_inflated', pos + 1))\n",
    "                pos += 2\n",
    "            elif ftype == 'peak_inflated':\n",
    "                indices.append((name, 'peak_inflated', pos + 1))\n",
    "                pos += 2\n",
    "            elif ftype == 'continuous':\n",
    "                indices.append((name, 'continuous', pos))\n",
    "                pos += 1\n",
    "            else:\n",
    "                pos += dim\n",
    "        return indices\n",
    "    \n",
    "    def print_info(self):\n",
    "        print(f\"\\nData dimensions: {self.get_dim()}\")\n",
    "        pos = 0\n",
    "        for name, ftype, dim in self.feature_info:\n",
    "            extra = \"\"\n",
    "            if name in self.log_transform:\n",
    "                extra = \" [LOG]\"\n",
    "            print(f\"  [{pos:3d}-{pos+dim-1:3d}] {name} ({ftype}){extra}\")\n",
    "            pos += dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 5. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, seed=42):\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, test_size=0.2, random_state=seed, stratify=df[TARGET]\n",
    "    )\n",
    "    \n",
    "    prep = Preprocessor()\n",
    "    prep.fit(train_df)\n",
    "    \n",
    "    X_train, y_train = prep.transform(train_df)\n",
    "    X_test, y_test = prep.transform(test_df)\n",
    "    \n",
    "    print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "    print(f\"Label distribution - Train: {np.bincount(y_train)/len(y_train)}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 6. GAN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator with skip connections and learned variance.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, output_dim, prep, hidden_dim=256, cond_dim=0):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.prep = prep\n",
    "        self.cond_dim = cond_dim\n",
    "        \n",
    "        input_dim = latent_dim + cond_dim\n",
    "        \n",
    "        # Main backbone with skip connections\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.ln1 = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim * 2)\n",
    "        self.ln2 = nn.LayerNorm(hidden_dim * 2)\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_dim * 2, hidden_dim * 2)\n",
    "        self.ln3 = nn.LayerNorm(hidden_dim * 2)\n",
    "        \n",
    "        # Skip connection projection\n",
    "        self.skip_proj = nn.Linear(hidden_dim, hidden_dim * 2)\n",
    "        \n",
    "        # Count continuous features for variance parameters\n",
    "        n_cont = sum(1 for _, ftype, _ in prep.feature_info \n",
    "                     if ftype in ['zero_inflated', 'peak_inflated', 'continuous'])\n",
    "        \n",
    "        # Output head (extra outputs for variance)\n",
    "        self.fc_out = nn.Linear(hidden_dim * 2, output_dim + n_cont)\n",
    "        \n",
    "        # Learnable per-feature scaling\n",
    "        self.cont_bias = nn.Parameter(torch.zeros(n_cont))\n",
    "        self.cont_scale = nn.Parameter(torch.ones(n_cont))\n",
    "        \n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "    \n",
    "    def forward(self, z, labels=None, temp=0.5, hard=False):\n",
    "        if self.cond_dim > 0 and labels is not None:\n",
    "            labels_onehot = F.one_hot(labels, self.cond_dim).float()\n",
    "            z = torch.cat([z, labels_onehot], dim=1)\n",
    "        \n",
    "        # Backbone with skip connection\n",
    "        h1 = self.activation(self.ln1(self.fc1(z)))\n",
    "        h2 = self.activation(self.ln2(self.fc2(h1)))\n",
    "        h3 = self.activation(self.ln3(self.fc3(h2)))\n",
    "        h3 = h3 + self.skip_proj(h1)  # Skip connection\n",
    "        \n",
    "        x = self.fc_out(h3)\n",
    "        \n",
    "        return self._apply_activations(x, temp, hard)\n",
    "    \n",
    "    def _apply_activations(self, x, temp, hard):\n",
    "        outputs = []\n",
    "        pos = 0\n",
    "        extra_pos = self.output_dim  # Variance params start here\n",
    "        cont_idx = 0\n",
    "        \n",
    "        for name, ftype, dim in self.prep.feature_info:\n",
    "            if ftype == 'zero_inflated':\n",
    "                is_zero_logit = x[:, pos]\n",
    "                value_logit = x[:, pos + 1]\n",
    "                log_var = x[:, extra_pos]\n",
    "                extra_pos += 1\n",
    "                \n",
    "                is_zero_prob = torch.sigmoid(is_zero_logit)\n",
    "                \n",
    "                # Base value with learned noise\n",
    "                base_val = torch.sigmoid(value_logit)\n",
    "                if self.training:\n",
    "                    noise = torch.randn_like(base_val) * torch.exp(0.5 * log_var) * 0.1\n",
    "                    value = torch.clamp(base_val + noise, 0, 1)\n",
    "                else:\n",
    "                    value = base_val\n",
    "                \n",
    "                # Apply learned scale/bias\n",
    "                value = value * self.cont_scale[cont_idx] + self.cont_bias[cont_idx]\n",
    "                value = torch.clamp(value, 0, 1)\n",
    "                cont_idx += 1\n",
    "                \n",
    "                if hard or not self.training:\n",
    "                    is_zero = (torch.rand_like(is_zero_prob) < is_zero_prob).float()\n",
    "                    # When is_zero=1, final_value=0 (matching encoding)\n",
    "                    final_value = (1 - is_zero) * value\n",
    "                    outputs.extend([is_zero.unsqueeze(1), final_value.unsqueeze(1)])\n",
    "                else:\n",
    "                    outputs.extend([is_zero_prob.unsqueeze(1), value.unsqueeze(1)])\n",
    "                \n",
    "                pos += 2\n",
    "                \n",
    "            elif ftype == 'peak_inflated':\n",
    "                is_peak_logit = x[:, pos]\n",
    "                value_logit = x[:, pos + 1]\n",
    "                log_var = x[:, extra_pos]\n",
    "                extra_pos += 1\n",
    "                \n",
    "                is_peak_prob = torch.sigmoid(is_peak_logit)\n",
    "                \n",
    "                # Base value with learned noise (wider for hours-per-week)\n",
    "                base_val = torch.sigmoid(value_logit)\n",
    "                if self.training:\n",
    "                    noise = torch.randn_like(base_val) * torch.exp(0.5 * log_var) * 0.15\n",
    "                    value = torch.clamp(base_val + noise, 0, 1)\n",
    "                else:\n",
    "                    noise = torch.randn_like(base_val) * 0.1\n",
    "                    value = torch.clamp(base_val + noise, 0, 1)\n",
    "                \n",
    "                # Apply learned scale/bias\n",
    "                value = value * self.cont_scale[cont_idx] + self.cont_bias[cont_idx]\n",
    "                value = torch.clamp(value, 0, 1)\n",
    "                cont_idx += 1\n",
    "                \n",
    "                if hard or not self.training:\n",
    "                    is_peak = (torch.rand_like(is_peak_prob) < is_peak_prob).float()\n",
    "                    # When is_peak=1, value=0.5 (matching encoding)\n",
    "                    final_value = is_peak * 0.5 + (1 - is_peak) * value\n",
    "                    outputs.extend([is_peak.unsqueeze(1), final_value.unsqueeze(1)])\n",
    "                else:\n",
    "                    outputs.extend([is_peak_prob.unsqueeze(1), value.unsqueeze(1)])\n",
    "                \n",
    "                pos += 2\n",
    "                \n",
    "            elif ftype == 'continuous':\n",
    "                value_logit = x[:, pos]\n",
    "                log_var = x[:, extra_pos]\n",
    "                extra_pos += 1\n",
    "                \n",
    "                base_val = torch.sigmoid(value_logit)\n",
    "                if self.training:\n",
    "                    noise = torch.randn_like(base_val) * torch.exp(0.5 * log_var) * 0.1\n",
    "                    value = torch.clamp(base_val + noise, 0, 1)\n",
    "                else:\n",
    "                    noise = torch.randn_like(base_val) * 0.05\n",
    "                    value = torch.clamp(base_val + noise, 0, 1)\n",
    "                \n",
    "                # Apply learned scale/bias\n",
    "                value = value * self.cont_scale[cont_idx] + self.cont_bias[cont_idx]\n",
    "                value = torch.clamp(value, 0, 1)\n",
    "                cont_idx += 1\n",
    "                \n",
    "                outputs.append(value.unsqueeze(1))\n",
    "                pos += 1\n",
    "                \n",
    "            elif ftype == 'categorical':\n",
    "                logits = x[:, pos:pos + dim]\n",
    "                if hard or not self.training:\n",
    "                    idx = logits.argmax(dim=-1, keepdim=True)\n",
    "                    onehot = torch.zeros_like(logits).scatter_(-1, idx, 1.0)\n",
    "                else:\n",
    "                    # Gumbel-softmax\n",
    "                    gumbels = -torch.log(-torch.log(torch.rand_like(logits) + 1e-20) + 1e-20)\n",
    "                    y = F.softmax((logits + gumbels) / temp, dim=-1)\n",
    "                    idx = y.argmax(dim=-1, keepdim=True)\n",
    "                    onehot = torch.zeros_like(logits).scatter_(-1, idx, 1.0)\n",
    "                    onehot = onehot - y.detach() + y  # straight-through\n",
    "                outputs.append(onehot)\n",
    "                pos += dim\n",
    "        \n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator with spectral normalization.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim=256, cond_dim=0, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.cond_dim = cond_dim\n",
    "        \n",
    "        total_input = input_dim + cond_dim\n",
    "        \n",
    "        self.fc1 = nn.utils.spectral_norm(nn.Linear(total_input, hidden_dim))\n",
    "        self.fc2 = nn.utils.spectral_norm(nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.fc3 = nn.utils.spectral_norm(nn.Linear(hidden_dim, hidden_dim // 2))\n",
    "        self.fc_out = nn.Linear(hidden_dim // 2, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "    \n",
    "    def forward(self, x, labels=None):\n",
    "        if self.cond_dim > 0 and labels is not None:\n",
    "            labels_onehot = F.one_hot(labels, self.cond_dim).float()\n",
    "            x = torch.cat([x, labels_onehot], dim=1)\n",
    "        \n",
    "        h = self.activation(self.fc1(x))\n",
    "        h = self.dropout(h)\n",
    "        h = self.activation(self.fc2(h))\n",
    "        h = self.dropout(h)\n",
    "        h = self.activation(self.fc3(h))\n",
    "        h = self.dropout(h)\n",
    "        return self.fc_out(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 7. Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(D, real, fake, labels, device):\n",
    "    \"\"\"WGAN-GP gradient penalty.\"\"\"\n",
    "    batch_size = real.size(0)\n",
    "    alpha = torch.rand(batch_size, 1, device=device).expand_as(real)\n",
    "    interp = (alpha * real + (1 - alpha) * fake).requires_grad_(True)\n",
    "    \n",
    "    d_out = D(interp, labels)\n",
    "    \n",
    "    grads = torch.autograd.grad(\n",
    "        outputs=d_out, inputs=interp,\n",
    "        grad_outputs=torch.ones_like(d_out),\n",
    "        create_graph=True, retain_graph=True\n",
    "    )[0]\n",
    "    \n",
    "    return ((grads.view(batch_size, -1).norm(2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "\n",
    "def proportion_loss(fake, prep):\n",
    "    \"\"\"Match proportions of zeros/peaks.\"\"\"\n",
    "    loss = 0.0\n",
    "    pos = 0\n",
    "    \n",
    "    for name, ftype, dim in prep.feature_info:\n",
    "        if ftype == 'zero_inflated':\n",
    "            pred_prop = fake[:, pos].mean()\n",
    "            target = prep.zero_props[name]\n",
    "            loss += (pred_prop - target) ** 2\n",
    "            pos += 2\n",
    "        elif ftype == 'peak_inflated':\n",
    "            pred_prop = fake[:, pos].mean()\n",
    "            target = prep.peak_props[name]\n",
    "            loss += (pred_prop - target) ** 2\n",
    "            pos += 2\n",
    "        elif ftype == 'continuous':\n",
    "            pos += 1\n",
    "        elif ftype == 'categorical':\n",
    "            pos += dim\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def quantile_loss(real, fake, prep, n_quantiles=20):\n",
    "    \"\"\"Match quantiles of continuous features.\"\"\"\n",
    "    loss = 0.0\n",
    "    cont_indices = prep.get_continuous_indices()\n",
    "    quantiles = torch.linspace(0.05, 0.95, n_quantiles)\n",
    "    \n",
    "    for name, ftype, idx in cont_indices:\n",
    "        real_col = real[:, idx]\n",
    "        fake_col = fake[:, idx]\n",
    "        \n",
    "        for q in quantiles:\n",
    "            real_q = torch.quantile(real_col, q.item())\n",
    "            fake_q = torch.quantile(fake_col, q.item())\n",
    "            loss += (real_q - fake_q) ** 2\n",
    "    \n",
    "    return loss / (len(cont_indices) * n_quantiles)\n",
    "\n",
    "\n",
    "def moment_loss(real, fake, prep):\n",
    "    \"\"\"Match mean, std, and skewness of continuous features.\"\"\"\n",
    "    loss = 0.0\n",
    "    cont_indices = prep.get_continuous_indices()\n",
    "    \n",
    "    for name, ftype, idx in cont_indices:\n",
    "        real_col = real[:, idx]\n",
    "        fake_col = fake[:, idx]\n",
    "        \n",
    "        # Mean\n",
    "        loss += (real_col.mean() - fake_col.mean()) ** 2\n",
    "        \n",
    "        # Std\n",
    "        loss += (real_col.std() - fake_col.std()) ** 2\n",
    "        \n",
    "        # Skewness\n",
    "        real_centered = real_col - real_col.mean()\n",
    "        fake_centered = fake_col - fake_col.mean()\n",
    "        real_skew = (real_centered ** 3).mean() / (real_col.std() ** 3 + 1e-8)\n",
    "        fake_skew = (fake_centered ** 3).mean() / (fake_col.std() ** 3 + 1e-8)\n",
    "        loss += 0.5 * (real_skew - fake_skew) ** 2\n",
    "    \n",
    "    return loss / len(cont_indices)\n",
    "\n",
    "\n",
    "def correlation_loss(real, fake, prep):\n",
    "    \"\"\"Preserve correlations between continuous features.\"\"\"\n",
    "    cont_indices = prep.get_continuous_indices()\n",
    "    indices = [idx for _, _, idx in cont_indices]\n",
    "    \n",
    "    if len(indices) < 2:\n",
    "        return torch.tensor(0.0, device=real.device)\n",
    "    \n",
    "    real_cont = real[:, indices]\n",
    "    fake_cont = fake[:, indices]\n",
    "    \n",
    "    def corrcoef(x):\n",
    "        x = x - x.mean(dim=0, keepdim=True)\n",
    "        x = x / (x.std(dim=0, keepdim=True) + 1e-8)\n",
    "        return torch.mm(x.T, x) / (x.shape[0] - 1)\n",
    "    \n",
    "    real_corr = corrcoef(real_cont)\n",
    "    fake_corr = corrcoef(fake_cont)\n",
    "    \n",
    "    return F.mse_loss(fake_corr, real_corr)\n",
    "\n",
    "\n",
    "def categorical_loss(real, fake, prep):\n",
    "    \"\"\"Match categorical frequency distributions.\"\"\"\n",
    "    loss = 0.0\n",
    "    pos = 0\n",
    "    n_cat = 0\n",
    "    \n",
    "    for name, ftype, dim in prep.feature_info:\n",
    "        if ftype == 'categorical':\n",
    "            fake_freq = fake[:, pos:pos + dim].mean(dim=0)\n",
    "            real_freq = real[:, pos:pos + dim].mean(dim=0)\n",
    "            loss += F.mse_loss(fake_freq, real_freq)\n",
    "            n_cat += 1\n",
    "            pos += dim\n",
    "        elif ftype in ['zero_inflated', 'peak_inflated']:\n",
    "            pos += 2\n",
    "        elif ftype == 'continuous':\n",
    "            pos += 1\n",
    "    \n",
    "    return loss / max(n_cat, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 8. Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(X_train, y_train, prep, \n",
    "              latent_dim=128, hidden_dim=256,\n",
    "              batch_size=256, epochs=300,\n",
    "              lr_g=2e-4, lr_d=1e-4, n_critic=5,\n",
    "              lambda_gp=10, lambda_prop=1.0,\n",
    "              lambda_quant=0.5, lambda_moment=0.5,\n",
    "              lambda_corr=1.0, lambda_cat=0.2,\n",
    "              conditional=False, seed=42):\n",
    "    \"\"\"\n",
    "    Train GAN or cGAN with multiple distribution matching losses.\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    \n",
    "    data_dim = prep.get_dim()\n",
    "    cond_dim = N_CLASSES if conditional else 0\n",
    "    \n",
    "    G = Generator(latent_dim, data_dim, prep, hidden_dim, cond_dim).to(device)\n",
    "    D = Discriminator(data_dim, hidden_dim, cond_dim).to(device)\n",
    "    \n",
    "    opt_g = optim.Adam(G.parameters(), lr=lr_g, betas=(0.5, 0.9))\n",
    "    opt_d = optim.Adam(D.parameters(), lr=lr_d, betas=(0.5, 0.9))\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X_train)\n",
    "    y_tensor = torch.LongTensor(y_train)\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    history = {'g_loss': [], 'd_loss': [], 'prop': [], 'quant': [], \n",
    "               'moment': [], 'corr': []}\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "        g_losses, d_losses = [], []\n",
    "        prop_losses, quant_losses, mom_losses, corr_losses = [], [], [], []\n",
    "        \n",
    "        for real_x, real_y in loader:\n",
    "            bs = real_x.size(0)\n",
    "            real_x = real_x.to(device)\n",
    "            real_y = real_y.to(device) if conditional else None\n",
    "            \n",
    "            # Train Discriminator\n",
    "            for _ in range(n_critic):\n",
    "                opt_d.zero_grad()\n",
    "                \n",
    "                z = torch.randn(bs, latent_dim, device=device)\n",
    "                fake_y = real_y if conditional else None\n",
    "                fake_x = G(z, fake_y, hard=False)\n",
    "                \n",
    "                # Trim to data_dim (exclude variance params)\n",
    "                fake_x_trim = fake_x[:, :data_dim]\n",
    "                \n",
    "                d_real = D(real_x, real_y)\n",
    "                d_fake = D(fake_x_trim.detach(), fake_y)\n",
    "                \n",
    "                gp = gradient_penalty(D, real_x, fake_x_trim.detach(), real_y, device)\n",
    "                d_loss = d_fake.mean() - d_real.mean() + lambda_gp * gp\n",
    "                \n",
    "                d_loss.backward()\n",
    "                opt_d.step()\n",
    "            \n",
    "            # Train Generator\n",
    "            opt_g.zero_grad()\n",
    "            \n",
    "            z = torch.randn(bs, latent_dim, device=device)\n",
    "            fake_x = G(z, fake_y, hard=False)\n",
    "            fake_x_trim = fake_x[:, :data_dim]\n",
    "            \n",
    "            # WGAN loss\n",
    "            g_loss_wgan = -D(fake_x_trim, fake_y).mean()\n",
    "            \n",
    "            # Auxiliary losses\n",
    "            p_loss = proportion_loss(fake_x_trim, prep)\n",
    "            q_loss = quantile_loss(real_x, fake_x_trim, prep)\n",
    "            m_loss = moment_loss(real_x, fake_x_trim, prep)\n",
    "            c_loss = correlation_loss(real_x, fake_x_trim, prep)\n",
    "            cat_loss = categorical_loss(real_x, fake_x_trim, prep)\n",
    "            \n",
    "            # Total loss\n",
    "            g_loss = (g_loss_wgan + \n",
    "                     lambda_prop * p_loss + \n",
    "                     lambda_quant * q_loss +\n",
    "                     lambda_moment * m_loss +\n",
    "                     lambda_corr * c_loss +\n",
    "                     lambda_cat * cat_loss)\n",
    "            \n",
    "            g_loss.backward()\n",
    "            opt_g.step()\n",
    "            \n",
    "            g_losses.append(g_loss_wgan.item())\n",
    "            d_losses.append(d_loss.item())\n",
    "            prop_losses.append(p_loss.item())\n",
    "            quant_losses.append(q_loss.item())\n",
    "            mom_losses.append(m_loss.item())\n",
    "            corr_losses.append(c_loss.item())\n",
    "        \n",
    "        history['g_loss'].append(np.mean(g_losses))\n",
    "        history['d_loss'].append(np.mean(d_losses))\n",
    "        history['prop'].append(np.mean(prop_losses))\n",
    "        history['quant'].append(np.mean(quant_losses))\n",
    "        history['moment'].append(np.mean(mom_losses))\n",
    "        history['corr'].append(np.mean(corr_losses))\n",
    "        \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}: D={history['d_loss'][-1]:.4f}, \"\n",
    "                  f\"G={history['g_loss'][-1]:.4f}, Q={history['quant'][-1]:.4f}\")\n",
    "    \n",
    "    return G, D, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 9. Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(G, n_samples, prep, labels=None):\n",
    "    \"\"\"Generate synthetic samples.\"\"\"\n",
    "    G.eval()\n",
    "    dev = next(G.parameters()).device\n",
    "    data_dim = prep.get_dim()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(n_samples, G.latent_dim, device=dev)\n",
    "        if labels is not None:\n",
    "            labels = torch.LongTensor(labels).to(dev)\n",
    "        fake = G(z, labels, hard=True)\n",
    "        # Trim to data_dim (exclude variance params)\n",
    "        fake = fake[:, :data_dim]\n",
    "    \n",
    "    return fake.cpu().numpy()\n",
    "\n",
    "\n",
    "def generate_with_label_ratio(G, n_samples, prep, label_ratio):\n",
    "    \"\"\"Generate cGAN samples with specific label ratio.\"\"\"\n",
    "    n_class0 = int(n_samples * label_ratio[0])\n",
    "    n_class1 = n_samples - n_class0\n",
    "    \n",
    "    labels = np.concatenate([np.zeros(n_class0), np.ones(n_class1)]).astype(int)\n",
    "    np.random.shuffle(labels)\n",
    "    \n",
    "    X_fake = generate(G, n_samples, prep, labels)\n",
    "    return X_fake, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 10. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_metric(X_real, X_fake, n_folds=4, seed=42):\n",
    "    \"\"\"Detection AUC: can RF distinguish real from synthetic?\"\"\"\n",
    "    y_real = np.zeros(len(X_real))\n",
    "    y_fake = np.ones(len(X_fake))\n",
    "    \n",
    "    X = np.vstack([X_real, X_fake])\n",
    "    y = np.concatenate([y_real, y_fake])\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    aucs = []\n",
    "    \n",
    "    for train_idx, test_idx in kf.split(X, y):\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=seed, n_jobs=-1)\n",
    "        rf.fit(X[train_idx], y[train_idx])\n",
    "        proba = rf.predict_proba(X[test_idx])[:, 1]\n",
    "        aucs.append(roc_auc_score(y[test_idx], proba))\n",
    "    \n",
    "    return np.mean(aucs), np.std(aucs)\n",
    "\n",
    "\n",
    "def efficacy_metric(X_train, y_train, X_fake, y_fake, X_test, y_test, seed=42):\n",
    "    \"\"\"Efficacy: is synthetic data useful for training?\"\"\"\n",
    "    # Train on real\n",
    "    rf_real = RandomForestClassifier(n_estimators=100, random_state=seed, n_jobs=-1)\n",
    "    rf_real.fit(X_train, y_train)\n",
    "    auc_real = roc_auc_score(y_test, rf_real.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    # Train on synthetic\n",
    "    rf_fake = RandomForestClassifier(n_estimators=100, random_state=seed, n_jobs=-1)\n",
    "    rf_fake.fit(X_fake, y_fake)\n",
    "    auc_fake = roc_auc_score(y_test, rf_fake.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    return auc_fake / auc_real, auc_real, auc_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 11. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": "def plot_losses(history, title, save_path=None):\n    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n    \n    axes[0, 0].plot(history['g_loss'], label='Generator')\n    axes[0, 0].plot(history['d_loss'], label='Discriminator')\n    axes[0, 0].set_title('GAN Losses')\n    axes[0, 0].legend()\n    axes[0, 0].grid(True, alpha=0.3)\n    \n    axes[0, 1].plot(history['prop'], color='green')\n    axes[0, 1].set_title('Proportion Loss')\n    axes[0, 1].grid(True, alpha=0.3)\n    \n    axes[0, 2].plot(history['quant'], color='purple')\n    axes[0, 2].set_title('Quantile Loss')\n    axes[0, 2].grid(True, alpha=0.3)\n    \n    axes[1, 0].plot(history['moment'], color='orange')\n    axes[1, 0].set_title('Moment Loss')\n    axes[1, 0].grid(True, alpha=0.3)\n    \n    axes[1, 1].plot(history['corr'], color='red')\n    axes[1, 1].set_title('Correlation Loss')\n    axes[1, 1].grid(True, alpha=0.3)\n    \n    axes[1, 2].axis('off')\n    \n    plt.suptitle(title)\n    plt.tight_layout()\n    if save_path:\n        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n    plt.show()\n\n\ndef plot_distributions(X_real, X_fake, prep, title, save_path=None):\n    \"\"\"Compare feature distributions.\"\"\"\n    # Get continuous feature indices\n    cont_features = prep.get_continuous_indices()\n    \n    n = len(cont_features)\n    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n    axes = axes.flatten()\n    \n    for i, (name, ftype, idx) in enumerate(cont_features[:6]):\n        ax = axes[i]\n        ax.hist(X_real[:, idx], bins=50, alpha=0.5, label='Real', density=True)\n        ax.hist(X_fake[:, idx], bins=50, alpha=0.5, label='Synthetic', density=True)\n        ax.set_title(f\"{name} ({ftype})\")\n        ax.legend()\n        ax.grid(True, alpha=0.3)\n    \n    for j in range(len(cont_features), 6):\n        axes[j].axis('off')\n    \n    plt.suptitle(title)\n    plt.tight_layout()\n    if save_path:\n        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n    plt.show()\n\n\ndef plot_correlation_matrix(X_real, X_fake, prep, title, save_path=None):\n    \"\"\"Plot correlation matrix difference between real and synthetic data.\"\"\"\n    # Get continuous feature indices and names\n    cont_features = prep.get_continuous_indices()\n    indices = [idx for _, _, idx in cont_features]\n    names = [name for name, _, _ in cont_features]\n    \n    if len(indices) < 2:\n        print(\"Not enough continuous features for correlation matrix\")\n        return\n    \n    # Extract continuous features\n    real_cont = X_real[:, indices]\n    fake_cont = X_fake[:, indices]\n    \n    # Compute correlation matrices\n    real_corr = np.corrcoef(real_cont.T)\n    fake_corr = np.corrcoef(fake_cont.T)\n    diff_corr = real_corr - fake_corr\n    \n    # Create figure with 3 subplots\n    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n    \n    # Real correlation matrix\n    im1 = axes[0].imshow(real_corr, cmap='RdBu_r', vmin=-1, vmax=1)\n    axes[0].set_title('Real Data Correlation')\n    axes[0].set_xticks(range(len(names)))\n    axes[0].set_yticks(range(len(names)))\n    axes[0].set_xticklabels(names, rotation=45, ha='right', fontsize=8)\n    axes[0].set_yticklabels(names, fontsize=8)\n    plt.colorbar(im1, ax=axes[0], shrink=0.8)\n    \n    # Synthetic correlation matrix\n    im2 = axes[1].imshow(fake_corr, cmap='RdBu_r', vmin=-1, vmax=1)\n    axes[1].set_title('Synthetic Data Correlation')\n    axes[1].set_xticks(range(len(names)))\n    axes[1].set_yticks(range(len(names)))\n    axes[1].set_xticklabels(names, rotation=45, ha='right', fontsize=8)\n    axes[1].set_yticklabels(names, fontsize=8)\n    plt.colorbar(im2, ax=axes[1], shrink=0.8)\n    \n    # Difference matrix\n    max_diff = max(abs(diff_corr.min()), abs(diff_corr.max()))\n    im3 = axes[2].imshow(diff_corr, cmap='RdBu_r', vmin=-max_diff, vmax=max_diff)\n    axes[2].set_title('Correlation Difference (Real - Synthetic)')\n    axes[2].set_xticks(range(len(names)))\n    axes[2].set_yticks(range(len(names)))\n    axes[2].set_xticklabels(names, rotation=45, ha='right', fontsize=8)\n    axes[2].set_yticklabels(names, fontsize=8)\n    plt.colorbar(im3, ax=axes[2], shrink=0.8)\n    \n    plt.suptitle(title)\n    plt.tight_layout()\n    if save_path:\n        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    # Print summary statistics\n    print(f\"\\nCorrelation Matrix Analysis:\")\n    print(f\"  Mean absolute difference: {np.abs(diff_corr).mean():.4f}\")\n    print(f\"  Max absolute difference: {np.abs(diff_corr).max():.4f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 12. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Latent dim: 128\n",
      "  Hidden dim: 256\n",
      "  Epochs: 300\n",
      "  Loss weights:\n",
      "    Proportion: 1.0\n",
      "    Quantile: 0.5\n",
      "    Moment: 0.5\n",
      "    Correlation: 1.0\n",
      "    Categorical: 0.2\n",
      "  Seeds: [42, 123, 456]\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "LATENT_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 300\n",
    "LR_G = 2e-4\n",
    "LR_D = 1e-4\n",
    "N_CRITIC = 5\n",
    "LAMBDA_GP = 10\n",
    "\n",
    "# Distribution matching loss weights\n",
    "LAMBDA_PROP = 1.0      # Proportion matching for zeros/peaks\n",
    "LAMBDA_QUANT = 0.5     # Quantile matching\n",
    "LAMBDA_MOMENT = 0.5    # Mean/std/skewness matching\n",
    "LAMBDA_CORR = 1.0      # Correlation preservation (important!)\n",
    "LAMBDA_CAT = 0.2       # Categorical frequency matching\n",
    "\n",
    "# Seeds for experiments\n",
    "SEEDS = [42, 123, 456]\n",
    "\n",
    "OUTPUT_DIR = '../outputs/final'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Latent dim: {LATENT_DIM}\")\n",
    "print(f\"  Hidden dim: {HIDDEN_DIM}\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Loss weights:\")\n",
    "print(f\"    Proportion: {LAMBDA_PROP}\")\n",
    "print(f\"    Quantile: {LAMBDA_QUANT}\")\n",
    "print(f\"    Moment: {LAMBDA_MOMENT}\")\n",
    "print(f\"    Correlation: {LAMBDA_CORR}\")\n",
    "print(f\"    Categorical: {LAMBDA_CAT}\")\n",
    "print(f\"  Seeds: {SEEDS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "\n",
    "# Part 1: Initial Comparison (Seed 42)\n",
    "Run one GAN and one cGAN first to compare approaches\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GAN - Seed 42\n",
      "============================================================\n",
      "Train: (26048, 123), Test: (6513, 123)\n",
      "Label distribution - Train: [0.75917537 0.24082463]\n",
      "\n",
      "Data dimensions: 123\n",
      "  [  0-  1] capital-gain (zero_inflated)\n",
      "  [  2-  3] capital-loss (zero_inflated)\n",
      "  [  4-  5] hours-per-week (peak_inflated)\n",
      "  [  6-  6] age (continuous)\n",
      "  [  7-  7] fnlwgt (continuous) [LOG]\n",
      "  [  8- 23] education-num (categorical)\n",
      "  [ 24- 31] workclass (categorical)\n",
      "  [ 32- 47] education (categorical)\n",
      "  [ 48- 54] marital-status (categorical)\n",
      "  [ 55- 68] occupation (categorical)\n",
      "  [ 69- 74] relationship (categorical)\n",
      "  [ 75- 79] race (categorical)\n",
      "  [ 80- 81] sex (categorical)\n",
      "  [ 82-122] native-country (categorical)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 50/300 [08:17<41:14,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: D=-0.2566, G=0.4422, Q=0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 100/300 [16:33<33:08,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: D=-0.2119, G=0.4132, Q=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 150/300 [24:45<24:11,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150: D=-0.1809, G=0.6492, Q=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 200/300 [33:00<16:34,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: D=-0.1727, G=0.6319, Q=0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████▎ | 250/300 [41:14<08:16,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250: D=-0.1641, G=0.7750, Q=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [49:22<00:00,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300: D=-0.1561, G=0.4852, Q=0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'prop_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     12\u001b[39m G_gan, D_gan, history_gan = train_gan(\n\u001b[32m     13\u001b[39m     X_train, y_train, prep,\n\u001b[32m     14\u001b[39m     latent_dim=LATENT_DIM, hidden_dim=HIDDEN_DIM,\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     conditional=\u001b[38;5;28;01mFalse\u001b[39;00m, seed=seed\n\u001b[32m     21\u001b[39m )\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Plot losses\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mplot_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory_gan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGAN Training (Seed \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mseed\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/gan_losses_seed\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mseed\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.png\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Generate synthetic data\u001b[39;00m\n\u001b[32m     28\u001b[39m X_fake_gan = generate(G_gan, \u001b[38;5;28mlen\u001b[39m(X_train), prep)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mplot_losses\u001b[39m\u001b[34m(history, title, save_path)\u001b[39m\n\u001b[32m      7\u001b[39m axes[\u001b[32m0\u001b[39m].legend()\n\u001b[32m      8\u001b[39m axes[\u001b[32m0\u001b[39m].grid(\u001b[38;5;28;01mTrue\u001b[39;00m, alpha=\u001b[32m0.3\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m axes[\u001b[32m1\u001b[39m].plot(\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprop_loss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, color=\u001b[33m'\u001b[39m\u001b[33mgreen\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     11\u001b[39m axes[\u001b[32m1\u001b[39m].set_title(\u001b[33m'\u001b[39m\u001b[33mProportion Loss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     12\u001b[39m axes[\u001b[32m1\u001b[39m].grid(\u001b[38;5;28;01mTrue\u001b[39;00m, alpha=\u001b[32m0.3\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'prop_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run GAN with seed 42\n",
    "seed = 42\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"GAN - Seed {seed}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test, prep = prepare_data(df, seed=seed)\n",
    "prep.print_info()\n",
    "\n",
    "# Train GAN\n",
    "G_gan, D_gan, history_gan = train_gan(\n",
    "    X_train, y_train, prep,\n",
    "    latent_dim=LATENT_DIM, hidden_dim=HIDDEN_DIM,\n",
    "    batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "    lr_g=LR_G, lr_d=LR_D, n_critic=N_CRITIC,\n",
    "    lambda_gp=LAMBDA_GP, lambda_prop=LAMBDA_PROP,\n",
    "    lambda_quant=LAMBDA_QUANT, lambda_moment=LAMBDA_MOMENT,\n",
    "    lambda_corr=LAMBDA_CORR, lambda_cat=LAMBDA_CAT,\n",
    "    conditional=False, seed=seed\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e03dc",
   "metadata": {},
   "outputs": [],
   "source": "# Plot losses\nplot_losses(history_gan, f\"GAN Training (Seed {seed})\", \n            f\"{OUTPUT_DIR}/gan_losses_seed{seed}.png\")\n\n# Generate synthetic data\nX_fake_gan = generate(G_gan, len(X_train), prep)\ny_fake_gan = y_train.copy()\n\n# Plot distributions\nplot_distributions(X_train, X_fake_gan, prep, f\"GAN Distributions (Seed {seed})\",\n                   f\"{OUTPUT_DIR}/gan_dist_seed{seed}.png\")\n\n# Plot correlation matrix difference\nplot_correlation_matrix(X_train, X_fake_gan, prep, f\"GAN Correlation Matrix (Seed {seed})\",\n                        f\"{OUTPUT_DIR}/gan_corr_seed{seed}.png\")\n\n# Evaluate\ndet_auc_gan, det_std_gan = detection_metric(X_train, X_fake_gan, seed=seed)\neff_gan, auc_real_gan, auc_fake_gan = efficacy_metric(X_train, y_train, X_fake_gan, y_fake_gan, X_test, y_test, seed=seed)\n\nprint(f\"\\nGAN Results (Seed {seed}):\")\nprint(f\"  Detection AUC: {det_auc_gan:.4f} (+/- {det_std_gan:.4f})\")\nprint(f\"  Efficacy: {eff_gan:.4f} (Real AUC: {auc_real_gan:.4f}, Synth AUC: {auc_fake_gan:.4f})\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": "# Run cGAN with seed 42\nseed = 42\nprint(f\"\\n{'='*60}\")\nprint(f\"cGAN - Seed {seed}\")\nprint(f\"{'='*60}\")\n\n# Get label ratio from training data\nlabel_counts = np.bincount(y_train)\nlabel_ratio = label_counts / len(y_train)\nprint(f\"Label ratio: {label_ratio}\")\n\n# Train cGAN\nG_cgan, D_cgan, history_cgan = train_gan(\n    X_train, y_train, prep,\n    latent_dim=LATENT_DIM, hidden_dim=HIDDEN_DIM,\n    batch_size=BATCH_SIZE, epochs=EPOCHS,\n    lr_g=LR_G, lr_d=LR_D, n_critic=N_CRITIC,\n    lambda_gp=LAMBDA_GP, lambda_prop=LAMBDA_PROP,\n    lambda_quant=LAMBDA_QUANT, lambda_moment=LAMBDA_MOMENT,\n    lambda_corr=LAMBDA_CORR, lambda_cat=LAMBDA_CAT,\n    conditional=True, seed=seed\n)\n\n# Plot losses\nplot_losses(history_cgan, f\"cGAN Training (Seed {seed})\",\n            f\"{OUTPUT_DIR}/cgan_losses_seed{seed}.png\")\n\n# Generate synthetic data with same label ratio\nX_fake_cgan, y_fake_cgan = generate_with_label_ratio(G_cgan, len(X_train), prep, label_ratio)\n\n# Plot distributions\nplot_distributions(X_train, X_fake_cgan, prep, f\"cGAN Distributions (Seed {seed})\",\n                   f\"{OUTPUT_DIR}/cgan_dist_seed{seed}.png\")\n\n# Plot correlation matrix difference\nplot_correlation_matrix(X_train, X_fake_cgan, prep, f\"cGAN Correlation Matrix (Seed {seed})\",\n                        f\"{OUTPUT_DIR}/cgan_corr_seed{seed}.png\")\n\n# Evaluate\ndet_auc_cgan, det_std_cgan = detection_metric(X_train, X_fake_cgan, seed=seed)\neff_cgan, auc_real_cgan, auc_fake_cgan = efficacy_metric(X_train, y_train, X_fake_cgan, y_fake_cgan, X_test, y_test, seed=seed)\n\nprint(f\"\\ncGAN Results (Seed {seed}):\")\nprint(f\"  Detection AUC: {det_auc_cgan:.4f} (+/- {det_std_cgan:.4f})\")\nprint(f\"  Efficacy: {eff_cgan:.4f} (Real AUC: {auc_real_cgan:.4f}, Synth AUC: {auc_fake_cgan:.4f})\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## Initial Comparison (Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "INITIAL COMPARISON (Seed 42)\n",
      "============================================================\n",
      "\n",
      "| Model | Detection AUC | Efficacy |\n",
      "|-------|---------------|----------|\n",
      "| GAN   | 0.8974 | 0.6089 |\n",
      "| cGAN  | 0.8694 | 0.9540 |\n",
      "\n",
      "Note: Lower Detection AUC is better (synthetic similar to real)\n",
      "Note: Higher Efficacy is better (synthetic useful for training)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INITIAL COMPARISON (Seed 42)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n| Model | Detection AUC | Efficacy |\")\n",
    "print(\"|-------|---------------|----------|\")\n",
    "print(f\"| GAN   | {det_auc_gan:.4f} | {eff_gan:.4f} |\")\n",
    "print(f\"| cGAN  | {det_auc_cgan:.4f} | {eff_cgan:.4f} |\")\n",
    "\n",
    "print(\"\\nNote: Lower Detection AUC is better (synthetic similar to real)\")\n",
    "print(\"Note: Higher Efficacy is better (synthetic useful for training)\")\n",
    "\n",
    "# Store results\n",
    "gan_results = [{'seed': 42, 'detection_auc': det_auc_gan, 'efficacy': eff_gan, \n",
    "                'auc_real': auc_real_gan, 'auc_synth': auc_fake_gan}]\n",
    "cgan_results = [{'seed': 42, 'detection_auc': det_auc_cgan, 'efficacy': eff_cgan,\n",
    "                 'auc_real': auc_real_cgan, 'auc_synth': auc_fake_cgan}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1937282a",
   "metadata": {},
   "source": [
    "# Part 2: Remaining Seeds (123, 456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GAN - Seed 123\n",
      "============================================================\n",
      "Train: (26048, 122), Test: (6513, 122)\n",
      "Label distribution - Train: [0.75917537 0.24082463]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 50/300 [08:07<38:53,  9.33s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: D=-0.1995, G=0.1112, Q=0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 100/300 [15:51<30:51,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: D=-0.1141, G=0.1306, Q=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 150/300 [23:30<22:47,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150: D=-0.0930, G=0.1273, Q=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 200/300 [30:57<14:27,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: D=-0.0714, G=0.0228, Q=0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████▎ | 250/300 [38:11<07:13,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250: D=-0.0671, G=0.3045, Q=0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [45:38<00:00,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300: D=-0.0626, G=0.4397, Q=0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results: Detection AUC: 0.8786, Efficacy: 0.5688\n",
      "\n",
      "============================================================\n",
      "GAN - Seed 456\n",
      "============================================================\n",
      "Train: (26048, 123), Test: (6513, 123)\n",
      "Label distribution - Train: [0.75917537 0.24082463]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 50/300 [07:36<37:58,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: D=-0.2467, G=1.2429, Q=0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 100/300 [15:13<30:25,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: D=-0.1864, G=1.2804, Q=0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 150/300 [22:50<22:55,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150: D=-0.0968, G=0.9252, Q=0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 200/300 [30:28<15:03,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: D=-0.0867, G=1.2484, Q=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████▎ | 250/300 [38:04<07:35,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250: D=-0.0864, G=1.3655, Q=0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [45:40<00:00,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300: D=-0.0733, G=1.6052, Q=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results: Detection AUC: 0.8774, Efficacy: 0.5286\n"
     ]
    }
   ],
   "source": [
    "# Run remaining GAN seeds\n",
    "for seed in [123, 456]:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"GAN - Seed {seed}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train, X_test, y_train, y_test, prep = prepare_data(df, seed=seed)\n",
    "    \n",
    "    # Train GAN\n",
    "    G, D, history = train_gan(\n",
    "        X_train, y_train, prep,\n",
    "        latent_dim=LATENT_DIM, hidden_dim=HIDDEN_DIM,\n",
    "        batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "        lr_g=LR_G, lr_d=LR_D, n_critic=N_CRITIC,\n",
    "        lambda_gp=LAMBDA_GP, lambda_prop=LAMBDA_PROP,\n",
    "        lambda_quant=LAMBDA_QUANT, lambda_moment=LAMBDA_MOMENT,\n",
    "        lambda_corr=LAMBDA_CORR, lambda_cat=LAMBDA_CAT,\n",
    "        conditional=False, seed=seed\n",
    "    )\n",
    "    \n",
    "    # Generate and evaluate\n",
    "    X_fake = generate(G, len(X_train), prep)\n",
    "    y_fake = y_train.copy()\n",
    "    \n",
    "    det_auc, det_std = detection_metric(X_train, X_fake, seed=seed)\n",
    "    eff, auc_real, auc_fake = efficacy_metric(X_train, y_train, X_fake, y_fake, X_test, y_test, seed=seed)\n",
    "    \n",
    "    print(f\"\\nResults: Detection AUC: {det_auc:.4f}, Efficacy: {eff:.4f}\")\n",
    "    \n",
    "    gan_results.append({\n",
    "        'seed': seed, 'detection_auc': det_auc, 'efficacy': eff,\n",
    "        'auc_real': auc_real, 'auc_synth': auc_fake\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "cGAN - Seed 123\n",
      "============================================================\n",
      "Train: (26048, 122), Test: (6513, 122)\n",
      "Label distribution - Train: [0.75917537 0.24082463]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 50/300 [07:41<38:23,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: D=-0.1624, G=-0.3692, Q=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 100/300 [15:22<30:41,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: D=-0.1057, G=-0.0539, Q=0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 150/300 [23:03<23:00,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150: D=-0.0846, G=-0.2115, Q=0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 200/300 [30:45<15:39,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: D=-0.0716, G=-0.2342, Q=0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████▎ | 250/300 [38:30<07:39,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250: D=-0.0617, G=-0.0569, Q=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [46:12<00:00,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300: D=-0.0559, G=-0.1363, Q=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results: Detection AUC: 0.8656, Efficacy: 0.9493\n",
      "\n",
      "============================================================\n",
      "cGAN - Seed 456\n",
      "============================================================\n",
      "Train: (26048, 123), Test: (6513, 123)\n",
      "Label distribution - Train: [0.75917537 0.24082463]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 50/300 [07:42<38:22,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: D=-0.1774, G=-0.6681, Q=0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 100/300 [15:23<30:45,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: D=-0.1262, G=-1.0880, Q=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 150/300 [23:17<23:51,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150: D=-0.0940, G=-1.1527, Q=0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 200/300 [31:10<15:59,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: D=-0.0766, G=-1.1894, Q=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████▎ | 250/300 [39:00<07:54,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250: D=-0.0599, G=-1.2884, Q=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [46:50<00:00,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300: D=-0.0676, G=-1.1293, Q=0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results: Detection AUC: 0.8734, Efficacy: 0.9491\n"
     ]
    }
   ],
   "source": [
    "# Run remaining cGAN seeds\n",
    "for seed in [123, 456]:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"cGAN - Seed {seed}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train, X_test, y_train, y_test, prep = prepare_data(df, seed=seed)\n",
    "    \n",
    "    # Get label ratio\n",
    "    label_counts = np.bincount(y_train)\n",
    "    label_ratio = label_counts / len(y_train)\n",
    "    \n",
    "    # Train cGAN\n",
    "    G, D, history = train_gan(\n",
    "        X_train, y_train, prep,\n",
    "        latent_dim=LATENT_DIM, hidden_dim=HIDDEN_DIM,\n",
    "        batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "        lr_g=LR_G, lr_d=LR_D, n_critic=N_CRITIC,\n",
    "        lambda_gp=LAMBDA_GP, lambda_prop=LAMBDA_PROP,\n",
    "        lambda_quant=LAMBDA_QUANT, lambda_moment=LAMBDA_MOMENT,\n",
    "        lambda_corr=LAMBDA_CORR, lambda_cat=LAMBDA_CAT,\n",
    "        conditional=True, seed=seed\n",
    "    )\n",
    "    \n",
    "    # Generate and evaluate\n",
    "    X_fake, y_fake = generate_with_label_ratio(G, len(X_train), prep, label_ratio)\n",
    "    \n",
    "    det_auc, det_std = detection_metric(X_train, X_fake, seed=seed)\n",
    "    eff, auc_real, auc_fake = efficacy_metric(X_train, y_train, X_fake, y_fake, X_test, y_test, seed=seed)\n",
    "    \n",
    "    print(f\"\\nResults: Detection AUC: {det_auc:.4f}, Efficacy: {eff:.4f}\")\n",
    "    \n",
    "    cgan_results.append({\n",
    "        'seed': seed, 'detection_auc': det_auc, 'efficacy': eff,\n",
    "        'auc_real': auc_real, 'auc_synth': auc_fake\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g3721g2pahi",
   "metadata": {},
   "source": [
    "\n",
    "# Final Summary\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "as2j7i8v0m",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL RESULTS (Average over 3 seeds)\n",
      "============================================================\n",
      "\n",
      "| Model | Detection AUC | Efficacy |\n",
      "|-------|---------------|----------|\n",
      "| GAN   | 0.8845 +/- 0.0112 | 0.5688 +/- 0.0402 |\n",
      "| cGAN  | 0.8694 +/- 0.0039 | 0.9508 +/- 0.0028 |\n",
      "\n",
      "\n",
      "Detailed GAN Results:\n",
      " seed  detection_auc  efficacy  auc_real  auc_synth\n",
      "   42       0.897388  0.608905  0.906197   0.551788\n",
      "  123       0.878550  0.568797  0.899608   0.511695\n",
      "  456       0.877421  0.528592  0.900077   0.475774\n",
      "\n",
      "\n",
      "Detailed cGAN Results:\n",
      " seed  detection_auc  efficacy  auc_real  auc_synth\n",
      "   42       0.869362  0.953974  0.906197   0.864488\n",
      "  123       0.865588  0.949255  0.899608   0.853957\n",
      "  456       0.873352  0.949053  0.900077   0.854221\n",
      "\n",
      "\n",
      "Note: Lower Detection AUC is better (synthetic similar to real)\n",
      "Note: Higher Efficacy is better (synthetic useful for training)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS (Average over 3 seeds)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "gan_df = pd.DataFrame(gan_results)\n",
    "cgan_df = pd.DataFrame(cgan_results)\n",
    "\n",
    "print(\"\\n| Model | Detection AUC | Efficacy |\")\n",
    "print(\"|-------|---------------|----------|\")\n",
    "print(f\"| GAN   | {gan_df['detection_auc'].mean():.4f} +/- {gan_df['detection_auc'].std():.4f} | {gan_df['efficacy'].mean():.4f} +/- {gan_df['efficacy'].std():.4f} |\")\n",
    "print(f\"| cGAN  | {cgan_df['detection_auc'].mean():.4f} +/- {cgan_df['detection_auc'].std():.4f} | {cgan_df['efficacy'].mean():.4f} +/- {cgan_df['efficacy'].std():.4f} |\")\n",
    "\n",
    "print(\"\\n\\nDetailed GAN Results:\")\n",
    "print(gan_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\nDetailed cGAN Results:\")\n",
    "print(cgan_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\nNote: Lower Detection AUC is better (synthetic similar to real)\")\n",
    "print(\"Note: Higher Efficacy is better (synthetic useful for training)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}